{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Jl5VCVic_6Nv",
        "cellView": "form"
      },
      "outputs": [],
      "source": [
        "%%time\n",
        "#@title install Dependencies\n",
        "model_name = \"esmfold.model\"\n",
        "import os, time\n",
        "if not os.path.isfile(model_name):\n",
        "  # download esmfold params\n",
        "  os.system(\"apt-get install aria2 -qq\")\n",
        "  os.system(f\"aria2c -q -x 16 https://colabfold.steineggerlab.workers.dev/esm/{model_name} &\")\n",
        "\n",
        "  if not os.path.isfile(\"finished_install\"):\n",
        "    print(\"installing esmfold...\")\n",
        "    # install libs\n",
        "    os.system(\"pip install -q omegaconf \\\"pytorch_lightning<2\\\" \\\"torch<2\\\" biopython ml_collections einops py3Dmol\")\n",
        "    os.system(\"pip install -q git+https://github.com/NVIDIA/dllogger.git\")\n",
        "\n",
        "    # install openfold\n",
        "    commit = \"6908936b68ae89f67755240e2f588c09ec31d4c8\"\n",
        "    os.system(f\"pip install -q git+https://github.com/aqlaboratory/openfold.git@{commit}\")\n",
        "\n",
        "    # install esmfold\n",
        "    os.system(f\"pip install -q git+https://github.com/sokrypton/esm.git\")\n",
        "    os.system(\"touch finished_install\")\n",
        "\n",
        "  # wait for Params to finish downloading...\n",
        "  while not os.path.isfile(model_name):\n",
        "    time.sleep(5)\n",
        "  if os.path.isfile(f\"{model_name}.aria2\"):\n",
        "    print(\"downloading params...\")\n",
        "  while os.path.isfile(f\"{model_name}.aria2\"):\n",
        "    time.sleep(5)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "tZ8zRHzzTBzR",
        "cellView": "form"
      },
      "outputs": [],
      "source": [
        "#@title Mount Google Drive\n",
        "from google.colab import drive\n",
        "drive.mount('/content/gdrive')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "B4b04UE4ijGR",
        "cellView": "form"
      },
      "outputs": [],
      "source": [
        "#@title Upload fasta file\n",
        "from Bio import SeqIO\n",
        "from google.colab import files\n",
        "\n",
        "uploaded = files.upload()\n",
        "\n",
        "seq_dict = dict()\n",
        "seq_dict_short = dict()\n",
        "\n",
        "for file in uploaded:\n",
        "  for seq_rec in SeqIO.parse(f\"./{file}\", \"fasta\"):\n",
        "    if len(seq_rec.seq) <= 400:\n",
        "      seq_dict_short[seq_rec.id.replace(\"|\",\"_\")] = str(seq_rec.seq)\n",
        "    else:\n",
        "      seq_dict[seq_rec.id.replace(\"|\",\"_\")] = str(seq_rec.seq)\n",
        "\n",
        "print(f\"{len(seq_dict)} sequences will be predicted using Google GPU unit.. \")\n",
        "print(f\"{len(seq_dict_short)} sequences will be predicted using Meta API.. \")"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#@title ##run **ESMFold**\n",
        "%%time\n",
        "\n",
        "output_folder = \"/content/gdrive/My Drive/\" #@param {type:\"string\"}\n",
        "output_folder = output_folder.strip(\"/\")\n",
        "\n",
        "from string import ascii_uppercase, ascii_lowercase\n",
        "import hashlib, re, os\n",
        "import numpy as np\n",
        "from jax.tree_util import tree_map\n",
        "import matplotlib.pyplot as plt\n",
        "from scipy.special import softmax\n",
        "import os\n",
        "\n",
        "def parse_output(output):\n",
        "  pae = (output[\"aligned_confidence_probs\"][0] * np.arange(64)).mean(-1) * 31\n",
        "  plddt = output[\"plddt\"][0,:,1]\n",
        "\n",
        "  bins = np.append(0,np.linspace(2.3125,21.6875,63))\n",
        "  sm_contacts = softmax(output[\"distogram_logits\"],-1)[0]\n",
        "  sm_contacts = sm_contacts[...,bins<8].sum(-1)\n",
        "  xyz = output[\"positions\"][-1,0,:,1]\n",
        "  mask = output[\"atom37_atom_exists\"][0,:,1] == 1\n",
        "  o = {\"pae\":pae[mask,:][:,mask],\n",
        "       \"plddt\":plddt[mask],\n",
        "       \"sm_contacts\":sm_contacts[mask,:][:,mask],\n",
        "       \"xyz\":xyz[mask]}\n",
        "  return o\n",
        "\n",
        "def get_hash(x):\n",
        "  return hashlib.sha1(x.encode()).hexdigest()\n",
        "\n",
        "alphabet_list = list(ascii_uppercase+ascii_lowercase)\n",
        "\n",
        "for job in seq_dict:\n",
        "  jobname = job\n",
        "  jobname = re.sub(r'\\W+', '', jobname)[:50]\n",
        "\n",
        "  sequence = seq_dict[job]\n",
        "  sequence = re.sub(\"[^A-Z:]\", \"\", sequence.replace(\"/\",\":\").upper())\n",
        "  sequence = re.sub(\":+\",\":\",sequence)\n",
        "  sequence = re.sub(\"^[:]+\",\"\",sequence)\n",
        "  sequence = re.sub(\"[:]+$\",\"\",sequence)\n",
        "  copies = 1\n",
        "  if copies == \"\" or copies <= 0: copies = 1\n",
        "  sequence = \":\".join([sequence] * copies)\n",
        "  num_recycles = 3\n",
        "  chain_linker = 25\n",
        "\n",
        "  ID = jobname+\"_\"+get_hash(sequence)[:5]\n",
        "  seqs = sequence.split(\":\")\n",
        "  lengths = [len(s) for s in seqs]\n",
        "  length = sum(lengths)\n",
        "  print(\"length\",length)\n",
        "\n",
        "  u_seqs = list(set(seqs))\n",
        "  if len(seqs) == 1: mode = \"mono\"\n",
        "  elif len(u_seqs) == 1: mode = \"homo\"\n",
        "  else: mode = \"hetero\"\n",
        "\n",
        "  if \"model\" not in dir():\n",
        "    import torch\n",
        "    model = torch.load(\"esmfold.model\")\n",
        "    model.eval().cuda().requires_grad_(False)\n",
        "\n",
        "  # optimized for Tesla T4\n",
        "  if length > 700:\n",
        "    model.set_chunk_size(64)\n",
        "  else:\n",
        "    model.set_chunk_size(128)\n",
        "\n",
        "  torch.cuda.empty_cache()\n",
        "  output = model.infer(sequence,\n",
        "                      num_recycles=num_recycles,\n",
        "                      chain_linker=\"X\"*chain_linker,\n",
        "                      residue_index_offset=512)\n",
        "\n",
        "  pdb_str = model.output_to_pdb(output)[0]\n",
        "  output = tree_map(lambda x: x.cpu().numpy(), output)\n",
        "  ptm = output[\"ptm\"][0]\n",
        "  plddt = output[\"plddt\"][0,...,1].mean()\n",
        "  O = parse_output(output)\n",
        "  print(f'ptm: {ptm:.3f} plddt: {plddt:.3f}')\n",
        "  os.system(f\"mkdir -p {ID}\")\n",
        "  prefix = f\"{ID}/ptm{ptm:.3f}_r{num_recycles}_default\"\n",
        "  np.savetxt(f\"{prefix}.pae.txt\",O[\"pae\"],\"%.3f\")\n",
        "  with open(f\"{prefix}.pdb\",\"w\") as out:\n",
        "    out.write(pdb_str)\n",
        "\n",
        "  with open(f'/{output_folder}/{job}.pdb', 'w') as f:\n",
        "    f.write(pdb_str)\n",
        "\n",
        "#Short sequences prediction\n",
        "done = set()\n",
        "while len(done) != len(seq_dict_short):\n",
        "\n",
        "  for seq_ID in seq_dict_short:\n",
        "    os.system(f\"curl -X POST --data '{seq_dict_short[seq_ID]}' https://api.esmatlas.com/foldSequence/v1/pdb/ > {seq_ID}.pdb\")\n",
        "\n",
        "    with open(f\"{seq_ID}.pdb\", \"r\") as file:\n",
        "      data = file.read()\n",
        "      if data.startswith(\"HEADER\"):\n",
        "        with open(f'/{output_folder}/{seq_ID}.pdb', 'w') as f:\n",
        "          f.write(data)\n",
        "        done.add(seq_ID)\n",
        "        print(f\"{seq_ID} done..\")"
      ],
      "metadata": {
        "id": "0RaZ9l8-AKeL",
        "cellView": "form"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [],
      "metadata": {
        "id": "cixIjok2ixDg"
      }
    }
  ]
}